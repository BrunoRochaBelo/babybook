name: ci

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

jobs:
  guardrails:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Guardrails (copy/storage/pricing)
        shell: bash
        run: |
          python - <<'PY'
          from __future__ import annotations

          import os
          import re
          import sys
          from dataclasses import dataclass
          from pathlib import Path


          @dataclass(frozen=True)
          class Rule:
              name: str
              pattern: re.Pattern[str]
              roots: list[Path]


          REPO_ROOT = Path.cwd()

          # Pastas/arquivos que nunca queremos varrer (artefatos e deps)
          SKIP_DIRS = {
              ".git",
              ".venv",
              "node_modules",
              "dist",
              "build",
              "coverage",
              ".turbo",
              ".wrangler",
          }

          # Arquivos explicitamente permitidos (legado/stub)
          ALLOWLIST_FILES = {
              (
                  REPO_ROOT
                  / "apps"
                  / "api"
                  / "babybook_api"
                  / "storage"
                  / "providers"
                  / "b2.py"
              ).resolve(),
          }


          def iter_files(root: Path) -> list[Path]:
              out: list[Path] = []
              if not root.exists():
                  return out
              for dirpath, dirnames, filenames in os.walk(root):
                  # prune in-place
                  dirnames[:] = [d for d in dirnames if d not in SKIP_DIRS]
                  for fn in filenames:
                      p = (Path(dirpath) / fn).resolve()
                      if p in ALLOWLIST_FILES:
                          continue
                      # ignorar bin√°rios comuns
                      if p.suffix.lower() in {
                          ".png",
                          ".jpg",
                          ".jpeg",
                          ".gif",
                          ".webp",
                          ".avif",
                          ".ico",
                          ".pdf",
                      }:
                          continue
                      out.append(p)
              return out


          def scan_rule(rule: Rule) -> list[tuple[Path, int, str]]:
              hits: list[tuple[Path, int, str]] = []
              for root in rule.roots:
                  for p in iter_files(root):
                      try:
                          text = p.read_text(encoding="utf-8", errors="ignore")
                      except Exception:
                          continue
                      for i, line in enumerate(text.splitlines(), start=1):
                          if rule.pattern.search(line):
                              hits.append((p, i, line.strip()))
              return hits


          rules: list[Rule] = [
              Rule(
                  name='Copy: n√£o pode voltar "at√© 12x"',
                  pattern=re.compile(r"(?i)\bat[e√©]\s*12x\b"),
                  roots=[
                      REPO_ROOT / "landingpage" / "src",
                      REPO_ROOT / "apps" / "web" / "src",
                      REPO_ROOT / "docs",
                  ],
              ),
              Rule(
                  name="Storage: remover Backblaze/Bandwidth Alliance do source",
                  pattern=re.compile(r"(?i)Backblaze|Bandwidth Alliance"),
                  roots=[
                      REPO_ROOT / "apps",
                      REPO_ROOT / "docs",
                      REPO_ROOT / "landingpage" / "src",
                      REPO_ROOT / "packages",
                  ],
              ),
              Rule(
                  name="Storage: n√£o pode voltar R2 h√≠brido",
                  pattern=re.compile(r"(?i)FEATURE_R2_HYBRID|r2_hybrid"),
                  roots=[
                      REPO_ROOT / "apps",
                      REPO_ROOT / "docs",
                      REPO_ROOT / "packages",
                  ],
              ),
          ]

          any_fail = False
          for rule in rules:
              hits = scan_rule(rule)
              if hits:
                  any_fail = True
                  print(f"\n‚ùå Guardrail violado: {rule.name}")
                  for p, line_no, line in hits[:50]:
                      rel = p.relative_to(REPO_ROOT)
                      print(f"- {rel}:{line_no}: {line}")
                  if len(hits) > 50:
                      print(f"‚Ä¶ +{len(hits) - 50} ocorr√™ncias")

          # Pricing can√¥nico (fonte √∫nica de verdade)
          pricing_file = (REPO_ROOT / "packages" / "config" / "pricing.ts")
          if pricing_file.exists():
              pricing_text = pricing_file.read_text(encoding="utf-8", errors="ignore")
              expected = {
                  "CARD": 29700,
                  "PIX": 27900,
              }
              for key, value in expected.items():
                  if not re.search(rf"\b{re.escape(key)}\s*:\s*{value}\b", pricing_text):
                      any_fail = True
                      rel = pricing_file.relative_to(REPO_ROOT)
                      print(
                          f"\n‚ùå Guardrail violado: pricing can√¥nico n√£o cont√©m {key}: {value} em {rel}"
                      )
          else:
              any_fail = True
              print("\n‚ùå Guardrail violado: packages/config/pricing.ts n√£o encontrado")

          if any_fail:
              print("\nGuardrails falharam. Corrija as ocorr√™ncias acima.")
              sys.exit(1)

          print("‚úÖ Guardrails OK")
          PY

  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
        with:
          version: 9
      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: pnpm
      - name: Install JS deps
        run: pnpm install
      - name: Lint JS/TS
        run: pnpm lint:js
      - name: Typecheck
        run: pnpm typecheck
      - name: Build landingpage
        run: pnpm --filter @babybook/landingpage run build:ci
      - name: Upload bundle stats
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: landingpage-stats
          path: landingpage/dist/stats.html
      - name: Comment bundle size on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            const historyPath = path.join(process.cwd(), 'landingpage', 'dist', 'budget-history.json');
            if (!fs.existsSync(historyPath)) return;
            const data = JSON.parse(fs.readFileSync(historyPath, 'utf-8'));
            const last = data[data.length - 1];
            const body = `üì¶ **Bundle Size Report**\n\n- JS: ${last.js.total.toFixed(1)} KB\n- CSS: ${last.css.total.toFixed(1)} KB\n- HTML: ${(last.html?.index || 0).toFixed(1)} KB\n\nWarnings: ${last.warnings}, Violations: ${last.violations}`;
            const pr = context.payload.pull_request;
            if (!pr) return;
            await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: pr.number, body });
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install API deps
        run: pip install -e apps/api[test]
      - name: Python lint
        run: pnpm lint:py
      # Upload distribution artifacts (always upload so artifacts are available on failure)
      - name: Upload landingpage dist (artifact)
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: landingpage-dist
          path: landingpage/dist
      - name: Upload budget history
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: landingpage-budget-history
          path: landingpage/dist/budget-history.json
      - name: Comment budget report on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            const historyPath = path.join(process.cwd(), 'landingpage', 'dist', 'budget-history.json');
            if (!fs.existsSync(historyPath)) return;
            const data = JSON.parse(fs.readFileSync(historyPath, 'utf-8'));
            const last = data[data.length - 1];
            const body = `Landingpage bundle report:\n\n- JS: ${last.js.total.toFixed(1)} KB\n- CSS: ${last.css.total.toFixed(1)} KB\n- Images: ${last.assets.images.toFixed(1)} KB\n- HTML (index): ${(last.html?.index || 0).toFixed(1)} KB\n\nWarnings: ${last.warnings}, Violations: ${last.violations}`;
            const pr = context.payload.pull_request;
            if (!pr) return;
            await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: pr.number, body });
      - name: Comment Lighthouse CI report on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            const pr = context.payload.pull_request;
            if (!pr) return;
            // Tenta ler o manifest do Lighthouse CI
            const manifestPath = path.join(process.cwd(), '.lighthouseci', 'manifest.json');
            let commentBody = '## üîç Lighthouse CI Report\n\n';

            if (fs.existsSync(manifestPath)) {
              try {
                const manifest = JSON.parse(fs.readFileSync(manifestPath, 'utf-8'));
                const firstRun = manifest[0];
                if (firstRun && firstRun.summary) {
                  const { performance, accessibility, 'best-practices': bestPractices, seo, pwa } = firstRun.summary;
                  
                  const getEmoji = (score) => {
                    if (score >= 0.9) return '‚úÖ';
                    if (score >= 0.5) return '‚ö†Ô∏è';
                    return '‚ùå';
                  };
                  
                  const formatScore = (score) => Math.round(score * 100);
                  
                  commentBody += '### Scores\n\n';
                  commentBody += `| Category | Score |\n`;
                  commentBody += `| --- | --- |\n`;
                  commentBody += `| ${getEmoji(performance)} Performance | ${formatScore(performance)} |\n`;
                  commentBody += `| ${getEmoji(accessibility)} Accessibility | ${formatScore(accessibility)} |\n`;
                  commentBody += `| ${getEmoji(bestPractices)} Best Practices | ${formatScore(bestPractices)} |\n`;
                  commentBody += `| ${getEmoji(seo)} SEO | ${formatScore(seo)} |\n`;
                  commentBody += `| ${getEmoji(pwa)} PWA | ${formatScore(pwa)} |\n\n`;
                  
                  if (firstRun.jsonPath) {
                    const reportPath = path.join(process.cwd(), firstRun.jsonPath);
                    if (fs.existsSync(reportPath)) {
                      const report = JSON.parse(fs.readFileSync(reportPath, 'utf-8'));
                      const audits = report.audits;
                      
                      commentBody += '### Key Metrics\n\n';
                      commentBody += `| Metric | Value |\n`;
                      commentBody += `| --- | --- |\n`;
                      
                      if (audits['first-contentful-paint']) {
                        commentBody += `| First Contentful Paint | ${audits['first-contentful-paint'].displayValue} |\n`;
                      }
                      if (audits['largest-contentful-paint']) {
                        commentBody += `| Largest Contentful Paint | ${audits['largest-contentful-paint'].displayValue} |\n`;
                      }
                      if (audits['cumulative-layout-shift']) {
                        commentBody += `| Cumulative Layout Shift | ${audits['cumulative-layout-shift'].displayValue} |\n`;
                      }
                      if (audits['total-blocking-time']) {
                        commentBody += `| Total Blocking Time | ${audits['total-blocking-time'].displayValue} |\n`;
                      }
                      if (audits['speed-index']) {
                        commentBody += `| Speed Index | ${audits['speed-index'].displayValue} |\n`;
                      }
                    }
                  }
                }
              } catch (error) {
                console.error('Error parsing Lighthouse results:', error);
                commentBody += '‚ö†Ô∏è Error parsing detailed results. Check artifacts for full report.\n\n';
              }
            } else {
              commentBody += '‚ö†Ô∏è Lighthouse manifest not found. Check artifacts on the workflow run for details.\n\n';
            }

            commentBody += '\nüìä [View full Lighthouse report in artifacts](';
            commentBody += `${context.payload.repository.html_url}/actions/runs/${context.runId})`;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.number,
              body: commentBody,
            });
